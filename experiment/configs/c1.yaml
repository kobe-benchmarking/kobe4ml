metadata:
  parent_id: kn7fej4o
  id: kn7fej4o_01
  version: v1
  name: BitBrain-LSTM-Autoencoder
  description: This run applies a LSTM autoencoder architecture that learns to reconstruct the BitBrain time series dataset.

implementation:
  module: lstm_ae

steps:
  - id: kn7fej4o_01_01
    type: prepare

    parameters:
      model_name: lstm_ae.pth 
      model_location: s3://manolo-data/models/

      model:
        num_feats: 2
        latent_seq_len: 1
        latent_num_feats: 8
        hidden_size: 4
        num_layers: 1
        dropout: 0.05

      process:
        seq_len: 240
        loss: BlendedLoss
        epochs: 2
        patience: 30
        lr: 0.0001
        optimizer: Adam
        scheduler:
          name: ReduceLROnPlateau
          params:
            factor: 0.99
            patience: 3

    data:
      loader: bitbrain_torch_loader
      location: s3://manolo-data/datasets/bitbrain-ds-empty/

      parameters:
        process: prepare
        batch_size: 512
        train_size: 2
        val_size: 1
        test_size: 1
        seq_len: 240
        exist: True

    metrics:
      - epochs
      - train_time
      - best_train_loss
      - best_val_loss
      - mae
      - mse

  - id: kn7fej4o_01_02
    type: work

    parameters:
      model_name: lstm_ae.pth 
      model_location: s3://manolo-data/models/

      model:
        num_feats: 2
        latent_seq_len: 1
        latent_num_feats: 8
        hidden_size: 4
        num_layers: 1
        dropout: 0.05

      process:
        seq_len: 240
        loss: BlendedLoss

    data:
      loader: bitbrain_torch_loader
      location: s3://manolo-data/datasets/bitbrain-ds-empty/

      parameters:
        process: work
        batch_size: 512
        train_size: 2
        val_size: 1
        test_size: 1
        seq_len: 240
        exist: True

    metrics:
      - mae
      - mse