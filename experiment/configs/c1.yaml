metadata:
  parent_id: kn7fej4o
  id: kn7fej4o_01
  version: v1
  name: BitBrain-LSTM-Autoencoder
  description: This run applies an LSTM autoencoder architecture that classifies
    time series into categorical classes on the BitBrain dataset.

implementation:
  module: lstm_ae

steps:
  - id: p_01
    type: prepare

    parameters:
      model_url: s3://manolo-data/models/lstm_ae.pth

      model:
        num_feats: 2
        latent_seq_len: 1
        latent_num_feats: 8
        hidden_size: 4
        num_layers: 1
        dropout: 0.05

      process:
        batch_size: 512
        seq_len: 240
        loss: BlendedLoss
        epochs: 1000
        patience: 30
        lr: 0.0001
        optimizer: Adam
        scheduler:
          name: ReduceLROnPlateau
          params:
            factor: 0.99
            patience: 3

    data:
      loader: bitbrain_torch_loader
      location: s3://manolo-data/datasets/bitbrain-ds/

      parameters:
        process: prepare
        batch_size: 512

    metrics:
      - epochs
      - train_time
      - best_train_loss
      - best_val_loss
      - mae
      - mse

  - id: i_01
    type: work

    parameters:
      model_url: s3://manolo-data/models/lstm_ae.pth

      model:
        num_feats: 2
        latent_seq_len: 1
        latent_num_feats: 8
        hidden_size: 4
        num_layers: 1
        dropout: 0.05

      process:
        batch_size: 512
        seq_len: 240
        loss: BlendedLoss

    data:
      loader: bitbrain_torch_loader
      location: s3://manolo-data/datasets/bitbrain-ds/

      parameters:
        process: work
        batch_size: 512

    metrics:
      - mae
      - mse