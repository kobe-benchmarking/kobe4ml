metadata:
  parent_id: kn7fej4o
  id: kn7fej4o_02
  version: v1
  name: BitBrain-LSTM-Autoencoder
  description: This run applies a Convolutional LSTM autoencoder architecture that learns to reconstruct the BitBrain time series dataset.

implementation:
  module: conv_lstm_ae

steps:
  - id: kn7fej4o_02_01
    type: prepare

    parameters:
      model_url: s3://manolo-data/models/conv_lstm_ae.pth

      model:
        num_feats: 2
        latent_seq_len: 1
        latent_num_feats: 8
        hidden_size: 4
        num_layers: 1
        dropout: 0.05

      process:
        seq_len: 240
        loss: BlendedLoss
        epochs: 2
        patience: 30
        lr: 0.0001
        optimizer: Adam
        scheduler:
          name: ReduceLROnPlateau
          params:
            factor: 0.99
            patience: 3

    data:
      loader: bitbrain_torch_loader
      location: s3://manolo-data/datasets/bitbrain-ds/

      parameters:
        process: prepare
        batch_size: 512

    metrics:
      - epochs
      - train_time
      - best_train_loss
      - best_val_loss
      - mae
      - mse

  - id: kn7fej4o_02_02
    type: work

    parameters:
      model_url: s3://manolo-data/models/conv_lstm_ae.pth

      model:
        num_feats: 2
        latent_seq_len: 1
        latent_num_feats: 8
        hidden_size: 4
        num_layers: 1
        dropout: 0.05

      process:
        seq_len: 240
        loss: BlendedLoss

    data:
      loader: bitbrain_torch_loader
      location: s3://manolo-data/datasets/bitbrain-ds/

      parameters:
        process: work
        batch_size: 512

    metrics:
      - mae
      - mse