metadata:
  experiment: kn7fej4o
  date: 06/03/2025
  name: BitBrain-LSTM-Autoencoder
  description: A paragraph-long description of this run. Here, this run applies an LSTM architecture that classifies timeseries into categorical classes on the BitBrain dataset.

implementation:
    module: lstm_ae
    # url: ...

run:
  id: kn7fej4o_01
  type: inference

  model: 
    name: LSTM_Autoencoder # check
    url: s3://manolo-data/models/lstm_ae.pth
    
    parameters:
      num_feats: 2
      latent_seq_len: 1 
      latent_num_feats: 8 
      hidden_size: 4
      num_layers: 1
      dropout: 0.05

  parameters:
    batch_size: 512
    seq_len: 240
    loss: BlendedLoss

  dataset:
    url: s3://manolo-data/datasets/bitbrain-ds/
  
  metrics:
    - module: mae
    - module: mse